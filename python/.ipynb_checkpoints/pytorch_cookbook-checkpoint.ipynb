{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Cookbook(常用代码段整理合集)![https://zhuanlan.zhihu.com/p/59205847]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "import os \n",
    "import shutil\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-57714bd2078e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 检查PyTorch版本\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# 检查PyTorch版本\n",
    "print(torch.__version__) \n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "# 1. 基础配置\n",
    "# 更新PyTorch\n",
    "#conda update pytorch torchvision -c pytorch\n",
    "\n",
    "# 固定随机种子\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "# 指定程序运行在特定GPU卡上\n",
    "# 命令行：\n",
    "# CUDA_VISIBLE_DEVICES=0,1 python trian.py\n",
    "\n",
    "# 代码指定：\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "# 判断是否有CUDA支持\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 设置cuDNN benchmark模式\n",
    "# Benchmark模式会提升计算速度，但是由于计算中有随机性，每次网络前馈结果略有差异\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# 如果想要避免这种结果波动，设置\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# 清除GPU存储\n",
    "# 有时control-c终止运行后GPU存储没有及时释放，需要手动清空\n",
    "torch.cuda.empty_cache()\n",
    "# 火灾命令行可以先使用ps找到程序的PID，再使用kill结束该进程\n",
    "# ps aux | grep python\n",
    "# kill -9 [pid]\n",
    "# 或者直接重置没有被清空的GPU\n",
    "# nvidia-smi --gpu-reset -i [gpu_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 张量处理\n",
    "## 定义张量\n",
    "\n",
    "    LongTensor; tensor --> torch.int64\n",
    "    Tensor; FloatTensor --> torch.float32\n",
    "    DoubleTensor --> torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.int64\n",
      "cpu\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 1D \n",
    "points = torch.tensor([1, 2, 3, 4])\n",
    "print(type(points)) # class\n",
    "print(points.dtype) # dtype\n",
    "print(points.device) # cpu or cuda\n",
    "\n",
    "# 2D \n",
    "points = torch.Tensor([[1, 2], [3, 4]]) # 大写T是float32\n",
    "print(points.dtype) # dtype\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 内存（Storage）\n",
    "     = 深拷贝\n",
    "     .clone() 浅拷贝\n",
    "     .t() 转置(共享一块内存，知识stride变了)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(2, 1)\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "points_storage = points.storage()\n",
    "offset = points[0, 1].storage_offset()\n",
    "print(offset)\n",
    "stride = points.stride()\n",
    "print(stride) # (row, col)\n",
    "\n",
    "points_t = points\n",
    "print(id(points_t) == id(points))\n",
    "\n",
    "points_t = points.clone()\n",
    "print(id(points_t) == id(points))\n",
    "\n",
    "points_t = points.t() # 转置不会分配新的内存，而是共享同一块内存，知识stride变了\n",
    "print(id(points_t.storage()) == id(points.storage()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3028,  0.1709,  0.7531, -0.6369,  0.6141],\n",
      "        [ 0.1843,  0.6579,  1.2402, -0.1499,  1.1012],\n",
      "        [-0.2528,  0.2208,  0.8031, -0.5869,  0.6641],\n",
      "        [-0.5499, -0.0763,  0.5060, -0.8841,  0.3670]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.5488, 0.7152, 0.6028, 0.5449, 0.4237]],\n",
       " \n",
       "         [[0.6459, 0.4376, 0.8918, 0.9637, 0.3834]],\n",
       " \n",
       "         [[0.7917, 0.5289, 0.5680, 0.9256, 0.0710]],\n",
       " \n",
       "         [[0.0871, 0.0202, 0.8326, 0.7782, 0.8700]]]),\n",
       " tensor([[0.9786, 0.7992, 0.4615, 0.7805, 0.1183],\n",
       "         [0.6399, 0.1434, 0.9447, 0.5218, 0.4147],\n",
       "         [0.2646, 0.7742, 0.4562, 0.5684, 0.0188],\n",
       "         [0.6176, 0.6121, 0.6169, 0.9437, 0.6818],\n",
       "         [0.3595, 0.4370, 0.6976, 0.0602, 0.6668]]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 张量基本信息\n",
    "tensor = torch.zeros(2,1,3)\n",
    "tensor.type()\n",
    "tensor.size()\n",
    "tensor.dim()\n",
    "\n",
    "# 数据类型转换\n",
    "# set default tensor type, float in pytorch is much faster than double\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "# type conversions\n",
    "tensor = tensor.cuda()\n",
    "tensor = tensor.cpu()\n",
    "tensor = tensor.float()\n",
    "tensor = tensor.long()\n",
    "\n",
    "# torch.Tensor与np.ndarray转换\n",
    "# PyTorch中的张量默认采用N×D×H×W的顺序，并且数据范围在[0, 1]，需要进行转置和规范化。\n",
    "ndarray = tensor.cpu().numpy()\n",
    "\n",
    "tensor = torch.from_numpy(ndarray.astype(np.float32)).to(device)\n",
    "tensor = torch.from_numpy(ndarray).float()\n",
    "tensor = torch.from_numpy(ndarray.copy()).float() # if ndarray has negative stride like np.array([1,2,3])[::-1] \n",
    "\n",
    "# torch.Tensor -> PIL.Image(H×W×D)\n",
    "image = PIL.Image.fromarray(torch.clamp(tensor*255, min=0, max=255).byte().permute(1, 2, 0).cpu().numpy())\n",
    "image = torchvision.transforms.functional.to_pil_image(tensor)\n",
    "\n",
    "# PIL.Image(H×W×D) -> torch.Tensor\n",
    "tensor = torch.from_numpy(np.asarray(PIL.Image.open(\"leslie2.jpg\"))).permute(2, 0, 1).float() / 255.\n",
    "tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(\"leslie2.jpg\"))\n",
    "\n",
    "# np.ndarray与PIL.Image转换\n",
    "# np.ndarray -> PIL.Image\n",
    "ndarray = np.random.random((2,2))\n",
    "image = PIL.Image.fromarray(ndarray.astype(np.uint8)) # uint(unsigned int)\n",
    "# PIL.Image -> np.ndarray\n",
    "ndarray = np.asarray(PIL.Image.open(\"leslie.jpg\"))\n",
    "\n",
    "# 从只包含一个元素的张量中提取值\n",
    "# 这在训练时统计loss的变化过程中特别有用，否则这将累积计算图，使GPU储存占用量越来越大。\n",
    "tensor = torch.zeros(1)\n",
    "value = tensor.item()\n",
    "\n",
    "# 张量形变: 张量形变常常用于将卷积层特征输入全连接层的情形，相比torch.view, torch.reshape可以自动处理输入张量不连续的情况，\n",
    "# tensor = torch.reshape(tensor, shape)\n",
    "\n",
    "# 打乱顺序\n",
    "tensor = torch.arange(20).reshape((1, 1, 4, 5))\n",
    "# print(tensor)\n",
    "#tensor = tensor[torch.randperm(tensor.size(0))] # shuffle the first dimension\n",
    "#print(tensor) # size == tensor.size(0)\n",
    "\n",
    "# 水平翻转: PyTorch不支持tensor[::-1]这样的负步长操作，水平翻转可以用张量索引实现\n",
    "# assume tensor has shape n*d*h*w\n",
    "# print(torch.arange(tensor.size(3)-1, -1, -1).long())\n",
    "tensor = tensor[:, :, :, torch.arange(tensor.size(3)-1, -1, -1).long()]\n",
    "# print(tensor)\n",
    "\n",
    "# 复制张量: 有三种复制的方式，对应不同的需求。\n",
    "# Operation                 |  New/Shared memory | Still in computation graph |\n",
    "tensor.clone()            # |        New         |          Yes               |\n",
    "tensor.detach()           # |      Shared        |          No                |\n",
    "tensor.detach().clone()   # |        New         |          No                |\n",
    "\n",
    "# 拼接张量\n",
    "# 注意torch.cat和torch.stack的区别在于torch.cat沿着给定的维度拼接，而torch.stack会新增一维。\n",
    "#tensor_2 = tensor.detach()\n",
    "#tensor = torch.cat([tensor, tensor_2], dim=0)\n",
    "#print(tensor.size())\n",
    "tensor_3 = torch.stack([tensor, tensor_2])\n",
    "# print(tensor_3.size())\n",
    "\n",
    "# 将整数标记转化独热(one-hot)编码\n",
    "# PyTorch中的标记默认从0开始\n",
    "tensor = torch.arange(10)\n",
    "# print(tensor)\n",
    "N = tensor.size(0)\n",
    "one_hot = torch.zeros(N, 10).long()\n",
    "# print(torch.unsqueeze(tensor, dim=1))\n",
    "one_hot.scatter_(dim=1, index=torch.unsqueeze(tensor, dim=1), src=torch.ones(N, 10).long())\n",
    "\n",
    "# 得到非零/零元素\n",
    "tensor = tensor *2\n",
    "# print(tensor==0) # tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.uint8)\n",
    "# print(torch.nonzero(tensor))     # Index of non-zero elements\n",
    "# print(torch.nonzero(tensor == 0))  # Index of zero elements\n",
    "torch.nonzero(tensor).size(0)\n",
    "torch.nonzero(tensor == 0).size(0)\n",
    "\n",
    "tensor = tensor.unsqueeze(dim=1)\n",
    "tensor1 = tensor.clone()\n",
    "# 判断两个张量相等\n",
    "torch.allclose(tensor1, tensor) # float tensor\n",
    "torch.equal(tensor1, tensor)\n",
    "\n",
    "tensor1 = tensor1.permute(1,0)\n",
    "\n",
    "# 矩阵乘法\n",
    "# Matrix multiplication: (m*n) * (n*p) -> (m*p).\n",
    "result = torch.mm(tensor1, tensor) \n",
    "tensor, tensor1 = tensor.unsqueeze(dim=0), tensor1.unsqueeze(dim=0)\n",
    "# print(tensor.size(), tensor1.size())\n",
    "\n",
    "# Batch matrix multiplication: (b*m*n) * (b*n*p) -> (b*m*p).\n",
    "result = torch.bmm(tensor1, tensor)\n",
    "\n",
    "# Elment-wise multiplication\n",
    "# result = tensor1 * tensor\n",
    "\n",
    "# 计算两组数据之间的两两欧式距离\n",
    "# X1 is of shape m*d, X2 is of shape n*d.\n",
    "np.random.seed(0)\n",
    "X1, X2 = torch.from_numpy(np.random.random((4, 5))).float(), torch.from_numpy(np.random.random((4, 5))).float()\n",
    "dist = torch.sqrt(torch.sum((X1[:,None,:] - X2) ** 2, dim=2))\n",
    "print(dist)\n",
    "X1[:,None,:], X2 # 添加维度[:,none,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numel\n",
    "    .numel() 返回元素个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([1, 2, 3, 4])\n",
    "num = points.numel()\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型定义（不能运行）"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 最常用y的卷积层配置\n",
    "conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "# 可视化工具\n",
    "# https://link.zhihu.com/?target=https%3A//ezyang.github.io/convolution-visualizer/index.html\n",
    "\n",
    "# GAP(Global average pooling)层\n",
    "gap = torch.nn.AdaptiveAvgPool2d(output_size=1)\n",
    "\n",
    "# 双线性汇合(bilinear pooling)\n",
    "X = torch.reshape(N, D, H * W)\n",
    "X = torch.bmm(X, torch.transpose(X, 1, 2)) / (H * W) # Bilinear pooling\n",
    "assert X.size() = (N, D, D)\n",
    "X = torch.reshape(X, (N, D*D))                       \n",
    "X = torch.sign(X) * torch.sqrt(torch.abs(X) + 1e-5)  # Signed-sqrt normalization\n",
    "X = torch.nn.functional.normalize(X)                 # L2 normalization\n",
    "\n",
    "# 多卡同步BN(Batch normalization)\n",
    "# 当使用torch.nn.DataParallel将代码运行在多张GPU卡上时，PyTorch的BN层默认操作是各卡上数据\n",
    "# 独立地计算均值和标准差，同步BN使用所有卡上的数据一起计算BN层的均值和标准差，缓解了当批量\n",
    "# 大小（batch size）比较小时对均值和标准差估计不准的情况，是在目标检测等任务中一个有效的\n",
    "# 提升性能的技巧。\n",
    "sync_bn = torch.nn.SyncBatchNorm(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "# 将已有网络的所有BN层改为同步BN层\n",
    "def convertBNtoSyncBN(module, process_group=None):\n",
    "    '''Recursively replace all BN layers to SyncBN layer.\n",
    "\n",
    "    Args:\n",
    "        module[torch.nn.Module]. Network\n",
    "    '''\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        sync_bn = torch.nn.SyncBatchNorm(module.num_features, module.eps, module.momentum, \n",
    "                                         module.affine, module.track_running_stats, process_group)\n",
    "        sync_bn.running_mean = module.running_mean\n",
    "        sync_bn.running_var = module.running_var\n",
    "        if module.affine:\n",
    "            sync_bn.weight = module.weight.clone().detach()\n",
    "            sync_bn.bias = module.bias.clone().detach()\n",
    "        return sync_bn\n",
    "    else:\n",
    "        for name, child_module in module.named_children():\n",
    "            setattr(module, name) = convert_syncbn_model(child_module, process_group=process_group))\n",
    "        return module\n",
    "    \n",
    "# 如果要实现类似BN滑动平均的操作，在forward函数中要使用原地（inplace）操作给滑动平均赋值。\n",
    "class BN(torch.nn.Module)\n",
    "    def __init__(self):\n",
    "        ...\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "\n",
    "    def forward(self, X):\n",
    "        ...\n",
    "        self.running_mean += momentum * (current - self.running_mean)\n",
    "\n",
    "# 计算模型整体参数量\n",
    "num_parameters = sum(torch.numel(parameter) for paramter in model.paramters())\n",
    "\n",
    "# 类似Keras的model.summary()输出模型信息\n",
    "# https://link.zhihu.com/?target=https%3A//github.com/sksq96/pytorch-summary\n",
    "\n",
    "# 模型权值初始化\n",
    "# 注意model.modules()和model.children()的区别：model.modules()会迭代地遍历模型的所有子层，\n",
    "# 而model.children()只会遍历模型下的一层。\n",
    "# Common practise for initialization.\n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(layer.weight, mode='fan_out',\n",
    "                                      nonlinearity='relu')\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "    elif isinstance(layer, torch.nn.BatchNorm2d):\n",
    "        torch.nn.init.constant_(layer.weight, val=1.0)\n",
    "        torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "    elif isinstance(layer, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(layer.weight)\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "\n",
    "# Initialization with given tensor.\n",
    "layer.weight = torch.nn.Parameter(tensor)\n",
    "\n",
    "# 部分层使用预训练模型\n",
    "# 注意如果保存的模型是torch.nn.DataParallel，则当前的模型也需要是torch.nn.DataParallel。\n",
    "# torch.nn.DataParallel(model).module == model。\n",
    "model.load_state_dict(torch.load('model.pth'), strict=False)\n",
    "# 将在GPU保存的模型加载到CPU\n",
    "model.load_state_dict(torch.load('model.pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network\n",
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "model = nn.Sequential(\n",
    "                nn.Linear(100, 128),\n",
    "                nn.ReLU(),\n",
    ")\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                ('linear', nn.Linear(100, 128)),\n",
    "                ('relu', nn.ReLU(),)\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6299, -0.1615, -1.0212],\n",
       "         [-0.5135,  1.4760, -0.0193],\n",
       "         [-1.4137,  0.9403,  0.8197],\n",
       "         [-1.1023,  1.1103,  1.6325]],\n",
       "\n",
       "        [[ 0.5707, -2.1696, -0.7352],\n",
       "         [ 0.7828,  0.4089,  1.1962],\n",
       "         [-0.3928,  0.3144,  0.0257],\n",
       "         [-1.9752, -0.5378, -0.3947]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn.Embedding(num_embeddings, embedding_dim) \n",
    "# num_embeddings (int) – size of the dictionary of embeddings\n",
    "# embedding_dim (int) – the size of each embedding vector\n",
    "embedding = nn.Embedding(10, 3)\n",
    "inputs = torch.LongTensor([[1,2,3,4],[5,6,7,8]])\n",
    "embedding(inputs) # 1-->[ 0.6762,  1.2037,  2.0559] 2-->[-0.5135,  1.4760, -0.0193],\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model info(#params, structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### name_parameters() and parameters()\n",
    "    [name, parameters] = model.name_parameters()\n",
    "    parameters = model.parameters()\n",
    "        # type(parameters) <class 'torch.nn.parameter.Parameter'>\n",
    "        # attr: requires_grad, shape, numel, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is the weight, its name: inconv.UConv.0.weight, its parameters: p, its num of paramters# 1728, shape: torch.Size([64, 3, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "for x, (n, p) in zip(model.parameters(), model.named_parameters()): # x is the weights\n",
    "        print(\"x is the weight, its name: {0}, its parameters: p, its num of paramters# {1}, shape: {2}\".format(n, p.numel(), p.shape))\n",
    "        print(type(x))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_info(model):  # Plots a line-by-line description of a PyTorch model\n",
    "    n_p = sum(x.numel() for x in model.parameters())  # number parameters\n",
    "    n_g = sum(x.numel() for x in model.parameters() if x.requires_grad)  # number gradients\n",
    "    print('\\n%5s %50s %9s %12s %20s %12s %12s' % ('layer', 'name', 'gradient', 'parameters', 'shape', 'mu', 'sigma'))\n",
    "    for i, (name, p) in enumerate(model.named_parameters()):\n",
    "        name = name.replace('module_list.', '')\n",
    "        print('%5g %50s %9s %12g %20s %12.3g %12.3g' % (\n",
    "            i, name, p.requires_grad, p.numel(), list(p.shape), p.mean(), p.std()))\n",
    "    print('Model Summary: %g layers, %g parameters, %g gradients\\n' % (i + 1, n_p, n_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential as S\n",
    "\"\"\"\n",
    "clear UNet implementation.\n",
    "\"\"\"\n",
    "class UNetConv(nn.Module):\n",
    "    \"\"\"\n",
    "    conv-bn-relu-conv-bn-relu\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(UNetConv, self).__init__()\n",
    "        self.UConv = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(c_out, c_out, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.UConv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"\n",
    "    Upscaling then double conv(implemented by https://github.com/milesial/Pytorch-UNet)\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out, bilinear=True):\n",
    "        super(Up, self).__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(c_in // 2, c_in // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = UNetConv(c_in, c_out)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, c_in, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        c_base = 16\n",
    "        self.inconv = UNetConv(c_in, c_base)\n",
    "        self.down_1 = S(nn.MaxPool2d(2), UNetConv(c_base, c_base*2),)\n",
    "        self.down_2 = S(nn.MaxPool2d(2), UNetConv(c_base*2, c_base*4),)\n",
    "        self.down_3 = S(nn.MaxPool2d(2), UNetConv(c_base*4, c_base*8),)\n",
    "        self.down_4 = S(nn.MaxPool2d(2), UNetConv(c_base*8, c_base*8),)\n",
    "        self.up_1 = Up(c_base*16, c_base*4, bilinear)\n",
    "        self.up_2 = Up(c_base*8, c_base*2, bilinear)\n",
    "        self.up_3 = Up(c_base*4, c_base*1, bilinear)\n",
    "        self.up_4 = Up(c_base*2, c_base*1, bilinear)\n",
    "        self.outconv = nn.Conv2d(c_base, n_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.inconv(x)\n",
    "        x2 = self.down_1(x1)\n",
    "        x3 = self.down_2(x2)\n",
    "        x4 = self.down_3(x3)\n",
    "        x5 = self.down_4(x4)\n",
    "        x = self.up_1(x5, x4)\n",
    "        x = self.up_2(x, x3)\n",
    "        x = self.up_3(x, x2)\n",
    "        x = self.up_4(x, x1)\n",
    "        logits = self.outconv(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "layer                                               name  gradient   parameters                shape           mu        sigma\n",
      "    0                              inconv.UConv.0.weight      True          432        [16, 3, 3, 3]      0.00164        0.116\n",
      "    1                              inconv.UConv.1.weight      True           16                 [16]            1            0\n",
      "    2                                inconv.UConv.1.bias      True           16                 [16]            0            0\n",
      "    3                              inconv.UConv.3.weight      True         2304       [16, 16, 3, 3]     0.000406        0.048\n",
      "    4                              inconv.UConv.4.weight      True           16                 [16]            1            0\n",
      "    5                                inconv.UConv.4.bias      True           16                 [16]            0            0\n",
      "    6                            down_1.1.UConv.0.weight      True         4608       [32, 16, 3, 3]     -0.00101       0.0484\n",
      "    7                            down_1.1.UConv.1.weight      True           32                 [32]            1            0\n",
      "    8                              down_1.1.UConv.1.bias      True           32                 [32]            0            0\n",
      "    9                            down_1.1.UConv.3.weight      True         9216       [32, 32, 3, 3]      9.5e-06       0.0338\n",
      "   10                            down_1.1.UConv.4.weight      True           32                 [32]            1            0\n",
      "   11                              down_1.1.UConv.4.bias      True           32                 [32]            0            0\n",
      "   12                            down_2.1.UConv.0.weight      True        18432       [64, 32, 3, 3]     0.000133       0.0341\n",
      "   13                            down_2.1.UConv.1.weight      True           64                 [64]            1            0\n",
      "   14                              down_2.1.UConv.1.bias      True           64                 [64]            0            0\n",
      "   15                            down_2.1.UConv.3.weight      True        36864       [64, 64, 3, 3]     9.85e-05       0.0241\n",
      "   16                            down_2.1.UConv.4.weight      True           64                 [64]            1            0\n",
      "   17                              down_2.1.UConv.4.bias      True           64                 [64]            0            0\n",
      "   18                            down_3.1.UConv.0.weight      True        73728      [128, 64, 3, 3]    -0.000117        0.024\n",
      "   19                            down_3.1.UConv.1.weight      True          128                [128]            1            0\n",
      "   20                              down_3.1.UConv.1.bias      True          128                [128]            0            0\n",
      "   21                            down_3.1.UConv.3.weight      True       147456     [128, 128, 3, 3]    -3.35e-05        0.017\n",
      "   22                            down_3.1.UConv.4.weight      True          128                [128]            1            0\n",
      "   23                              down_3.1.UConv.4.bias      True          128                [128]            0            0\n",
      "   24                            down_4.1.UConv.0.weight      True       147456     [128, 128, 3, 3]     1.82e-05        0.017\n",
      "   25                            down_4.1.UConv.1.weight      True          128                [128]            1            0\n",
      "   26                              down_4.1.UConv.1.bias      True          128                [128]            0            0\n",
      "   27                            down_4.1.UConv.3.weight      True       147456     [128, 128, 3, 3]     6.92e-05        0.017\n",
      "   28                            down_4.1.UConv.4.weight      True          128                [128]            1            0\n",
      "   29                              down_4.1.UConv.4.bias      True          128                [128]            0            0\n",
      "   30                           up_1.conv.UConv.0.weight      True       147456      [64, 256, 3, 3]    -4.22e-05        0.012\n",
      "   31                           up_1.conv.UConv.1.weight      True           64                 [64]            1            0\n",
      "   32                             up_1.conv.UConv.1.bias      True           64                 [64]            0            0\n",
      "   33                           up_1.conv.UConv.3.weight      True        36864       [64, 64, 3, 3]     0.000116        0.024\n",
      "   34                           up_1.conv.UConv.4.weight      True           64                 [64]            1            0\n",
      "   35                             up_1.conv.UConv.4.bias      True           64                 [64]            0            0\n",
      "   36                           up_2.conv.UConv.0.weight      True        36864      [32, 128, 3, 3]     5.58e-05        0.017\n",
      "   37                           up_2.conv.UConv.1.weight      True           32                 [32]            1            0\n",
      "   38                             up_2.conv.UConv.1.bias      True           32                 [32]            0            0\n",
      "   39                           up_2.conv.UConv.3.weight      True         9216       [32, 32, 3, 3]    -0.000248       0.0341\n",
      "   40                           up_2.conv.UConv.4.weight      True           32                 [32]            1            0\n",
      "   41                             up_2.conv.UConv.4.bias      True           32                 [32]            0            0\n",
      "   42                           up_3.conv.UConv.0.weight      True         9216       [16, 64, 3, 3]    -6.35e-06       0.0241\n",
      "   43                           up_3.conv.UConv.1.weight      True           16                 [16]            1            0\n",
      "   44                             up_3.conv.UConv.1.bias      True           16                 [16]            0            0\n",
      "   45                           up_3.conv.UConv.3.weight      True         2304       [16, 16, 3, 3]      0.00162        0.048\n",
      "   46                           up_3.conv.UConv.4.weight      True           16                 [16]            1            0\n",
      "   47                             up_3.conv.UConv.4.bias      True           16                 [16]            0            0\n",
      "   48                           up_4.conv.UConv.0.weight      True         4608       [16, 32, 3, 3]     0.000665       0.0341\n",
      "   49                           up_4.conv.UConv.1.weight      True           16                 [16]            1            0\n",
      "   50                             up_4.conv.UConv.1.bias      True           16                 [16]            0            0\n",
      "   51                           up_4.conv.UConv.3.weight      True         2304       [16, 16, 3, 3]    -0.000566       0.0483\n",
      "   52                           up_4.conv.UConv.4.weight      True           16                 [16]            1            0\n",
      "   53                             up_4.conv.UConv.4.bias      True           16                 [16]            0            0\n",
      "   54                                     outconv.weight      True          160       [10, 16, 1, 1]       0.0132        0.149\n",
      "   55                                       outconv.bias      True           10                 [10]     -0.00909        0.155\n",
      "Model Summary: 56 layers, 838938 parameters, 838938 gradients\n",
      "\n",
      "0.024000167846679688\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import time\n",
    "model = UNet(3, 10)\n",
    "model_info(model)\n",
    "inp = torch.from_numpy(np.random.normal(0, 1, [1, 3, 64, 64]).astype(np.float32))\n",
    "s = time.time()\n",
    "preds = model(inp)\n",
    "e = time.time()\n",
    "print(e-s)\n",
    "# print(preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Coordinates within Heatmap Regeression Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential as S\n",
    "\"\"\"\n",
    "clear UNet implementation.\n",
    "\"\"\"\n",
    "class UNetConv(nn.Module):\n",
    "    \"\"\"\n",
    "    conv-bn-relu-conv-bn-relu\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(UNetConv, self).__init__()\n",
    "        self.UConv = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(c_out, c_out, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.UConv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"\n",
    "    Upscaling then double conv(implemented by https://github.com/milesial/Pytorch-UNet)\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out, bilinear=True):\n",
    "        super(Up, self).__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(c_in // 2, c_in // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = UNetConv(c_in, c_out)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        \n",
    "        return self.conv(x)\n",
    "\n",
    "class NHCHRConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Contains X-axis and Y-axis Map and Heatmap Conv\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, c_in, c_out, bilinear=True):\n",
    "        super(NHCHRConv, self).__init__()\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(c_in // 2, c_in // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.HConv = UNetConv(c_in, c_out)\n",
    "        self.XConv = UNetConv(c_in, c_out)\n",
    "        self.YConv = UNetConv(c_in, c_out)\n",
    "\n",
    "    def conv_pad_cat(self, conv, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "\n",
    "        return conv(x)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        HOut = self.conv_pad_cat(self.HConv, x1, x2)\n",
    "        XOut = self.conv_pad_cat(self.XConv, x1, x2)\n",
    "        YOut = self.conv_pad_cat(self.YConv, x1, x2)\n",
    "\n",
    "        return HOut, XOut, YOut\n",
    "\n",
    "\n",
    "class NCHRNet(nn.Module):\n",
    "    def __init__(self, c_in, n_classes, bilinear=True):\n",
    "        super(NCHRNet, self).__init__()\n",
    "\n",
    "        c_base = 16\n",
    "        # self.f = 13.675*64\n",
    "        self.inconv = UNetConv(c_in, c_base)\n",
    "        self.down_1 = S(nn.MaxPool2d(2), UNetConv(c_base, c_base * 2), )\n",
    "        self.down_2 = S(nn.MaxPool2d(2), UNetConv(c_base * 2, c_base * 4), )\n",
    "        self.down_3 = S(nn.MaxPool2d(2), UNetConv(c_base * 4, c_base * 8), )\n",
    "        self.down_4 = S(nn.MaxPool2d(2), UNetConv(c_base * 8, c_base * 8), )\n",
    "        self.up_1 = Up(c_base * 16, c_base * 4, bilinear)\n",
    "        self.up_2 = Up(c_base * 8, c_base * 2, bilinear)\n",
    "        self.up_3 = Up(c_base * 4, c_base * 1, bilinear)\n",
    "        self.NHCHRConv = NHCHRConv(c_base * 2, c_base * 1, bilinear)\n",
    "        self.HOutconv = nn.Conv2d(c_base, n_classes, kernel_size=1)\n",
    "        self.XOutconv = S(\n",
    "            nn.Conv2d(c_base+1, 1, kernel_size=1),)\n",
    "#             nn.BatchNorm2d(9),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(9, 1, kernel_size=1))\n",
    "        self.YOutconv = S(\n",
    "            nn.Conv2d(c_base+1, 1, kernel_size=1),)\n",
    "#             nn.BatchNorm2d(9),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(9, 1, kernel_size=1))\n",
    "\n",
    "\n",
    "        # for m in self.modules():\n",
    "        #     if isinstance(m, nn.Conv2d):\n",
    "        #         n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        #         m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        #     elif isinstance(m, nn.BatchNorm2d):\n",
    "        #         m.weight.data.fill_(1)\n",
    "        #         m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inconv(x)\n",
    "        x2 = self.down_1(x1)\n",
    "        x3 = self.down_2(x2)\n",
    "        x4 = self.down_3(x3)\n",
    "        x5 = self.down_4(x4)\n",
    "        x = self.up_1(x5, x4)\n",
    "        x = self.up_2(x, x3)\n",
    "        x = self.up_3(x, x2)\n",
    "        H, X, Y = self.NHCHRConv(x, x1)\n",
    "\n",
    "        H = self.HOutconv(H)  # final heatmap prediction\n",
    "        X = self.XOutconv(torch.cat([H, X],dim=1))  # intermediate x-axis map (2-d)\n",
    "        Y = self.YOutconv(torch.cat([H, Y],dim=1))  # intermediate y-axis map (2-d)\n",
    "        # print(X[0,:,:,:])\n",
    "        # GET FINAL NUMERICAL COORDINATES\n",
    "        # x = torch.sum(H * X, dim=(1, 2, 3), keepdims=True).view(-1, 1) / self.f\n",
    "        # y = torch.sum(H * Y, dim=(1, 2, 3), keepdims=True).view(-1, 1) / self.f\n",
    "\n",
    "        # x = (H * X).sum(3).sum(2).sum(1).view(-1, 1) / self.f\n",
    "        # y = (H * Y).sum(3).sum(2).sum(1).view(-1, 1) / self.f\n",
    "        x = F.adaptive_avg_pool2d(X, (1,1)).view(-1,1)\n",
    "        y = F.adaptive_avg_pool2d(Y, (1,1)).view(-1,1)\n",
    "        coordinates = torch.cat([x, y], dim=1)\n",
    "\n",
    "        return H, coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 64, 64]) torch.Size([10, 2])\n",
      "inconv.UConv.0.weight False\n",
      "inconv.UConv.1.weight False\n",
      "inconv.UConv.1.bias False\n",
      "inconv.UConv.3.weight False\n",
      "inconv.UConv.4.weight False\n",
      "inconv.UConv.4.bias False\n",
      "down_1.1.UConv.0.weight False\n",
      "down_1.1.UConv.1.weight False\n",
      "down_1.1.UConv.1.bias False\n",
      "down_1.1.UConv.3.weight False\n",
      "down_1.1.UConv.4.weight False\n",
      "down_1.1.UConv.4.bias False\n",
      "down_2.1.UConv.0.weight False\n",
      "down_2.1.UConv.1.weight False\n",
      "down_2.1.UConv.1.bias False\n",
      "down_2.1.UConv.3.weight False\n",
      "down_2.1.UConv.4.weight False\n",
      "down_2.1.UConv.4.bias False\n",
      "down_3.1.UConv.0.weight False\n",
      "down_3.1.UConv.1.weight False\n",
      "down_3.1.UConv.1.bias False\n",
      "down_3.1.UConv.3.weight False\n",
      "down_3.1.UConv.4.weight False\n",
      "down_3.1.UConv.4.bias False\n",
      "down_4.1.UConv.0.weight False\n",
      "down_4.1.UConv.1.weight False\n",
      "down_4.1.UConv.1.bias False\n",
      "down_4.1.UConv.3.weight False\n",
      "down_4.1.UConv.4.weight False\n",
      "down_4.1.UConv.4.bias False\n",
      "up_1.conv.UConv.0.weight False\n",
      "up_1.conv.UConv.1.weight False\n",
      "up_1.conv.UConv.1.bias False\n",
      "up_1.conv.UConv.3.weight False\n",
      "up_1.conv.UConv.4.weight False\n",
      "up_1.conv.UConv.4.bias False\n",
      "up_2.conv.UConv.0.weight False\n",
      "up_2.conv.UConv.1.weight False\n",
      "up_2.conv.UConv.1.bias False\n",
      "up_2.conv.UConv.3.weight False\n",
      "up_2.conv.UConv.4.weight False\n",
      "up_2.conv.UConv.4.bias False\n",
      "up_3.conv.UConv.0.weight False\n",
      "up_3.conv.UConv.1.weight False\n",
      "up_3.conv.UConv.1.bias False\n",
      "up_3.conv.UConv.3.weight False\n",
      "up_3.conv.UConv.4.weight False\n",
      "up_3.conv.UConv.4.bias False\n",
      "NHCHRConv.HConv.UConv.0.weight False\n",
      "NHCHRConv.HConv.UConv.1.weight False\n",
      "NHCHRConv.HConv.UConv.1.bias False\n",
      "NHCHRConv.HConv.UConv.3.weight False\n",
      "NHCHRConv.HConv.UConv.4.weight False\n",
      "NHCHRConv.HConv.UConv.4.bias False\n",
      "NHCHRConv.XConv.UConv.0.weight True\n",
      "NHCHRConv.XConv.UConv.1.weight True\n",
      "NHCHRConv.XConv.UConv.1.bias True\n",
      "NHCHRConv.XConv.UConv.3.weight True\n",
      "NHCHRConv.XConv.UConv.4.weight True\n",
      "NHCHRConv.XConv.UConv.4.bias True\n",
      "NHCHRConv.YConv.UConv.0.weight True\n",
      "NHCHRConv.YConv.UConv.1.weight True\n",
      "NHCHRConv.YConv.UConv.1.bias True\n",
      "NHCHRConv.YConv.UConv.3.weight True\n",
      "NHCHRConv.YConv.UConv.4.weight True\n",
      "NHCHRConv.YConv.UConv.4.bias True\n",
      "HOutconv.weight False\n",
      "HOutconv.bias False\n",
      "XOutconv.0.weight True\n",
      "XOutconv.0.bias True\n",
      "YOutconv.0.weight True\n",
      "YOutconv.0.bias True\n",
      "\n",
      "layer                                               name  gradient   parameters                shape           mu        sigma\n",
      "    0                              inconv.UConv.0.weight     False          144        [16, 1, 3, 3]      -0.0138        0.184\n",
      "    1                              inconv.UConv.1.weight     False           16                 [16]            1            0\n",
      "    2                                inconv.UConv.1.bias     False           16                 [16]            0            0\n",
      "    3                              inconv.UConv.3.weight     False         2304       [16, 16, 3, 3]      0.00146       0.0487\n",
      "    4                              inconv.UConv.4.weight     False           16                 [16]            1            0\n",
      "    5                                inconv.UConv.4.bias     False           16                 [16]            0            0\n",
      "    6                            down_1.1.UConv.0.weight     False         4608       [32, 16, 3, 3]     -0.00118       0.0483\n",
      "    7                            down_1.1.UConv.1.weight     False           32                 [32]            1            0\n",
      "    8                              down_1.1.UConv.1.bias     False           32                 [32]            0            0\n",
      "    9                            down_1.1.UConv.3.weight     False         9216       [32, 32, 3, 3]     0.000781       0.0342\n",
      "   10                            down_1.1.UConv.4.weight     False           32                 [32]            1            0\n",
      "   11                              down_1.1.UConv.4.bias     False           32                 [32]            0            0\n",
      "   12                            down_2.1.UConv.0.weight     False        18432       [64, 32, 3, 3]      0.00022       0.0341\n",
      "   13                            down_2.1.UConv.1.weight     False           64                 [64]            1            0\n",
      "   14                              down_2.1.UConv.1.bias     False           64                 [64]            0            0\n",
      "   15                            down_2.1.UConv.3.weight     False        36864       [64, 64, 3, 3]     3.03e-05       0.0241\n",
      "   16                            down_2.1.UConv.4.weight     False           64                 [64]            1            0\n",
      "   17                              down_2.1.UConv.4.bias     False           64                 [64]            0            0\n",
      "   18                            down_3.1.UConv.0.weight     False        73728      [128, 64, 3, 3]     2.41e-05       0.0241\n",
      "   19                            down_3.1.UConv.1.weight     False          128                [128]            1            0\n",
      "   20                              down_3.1.UConv.1.bias     False          128                [128]            0            0\n",
      "   21                            down_3.1.UConv.3.weight     False       147456     [128, 128, 3, 3]     7.65e-06       0.0171\n",
      "   22                            down_3.1.UConv.4.weight     False          128                [128]            1            0\n",
      "   23                              down_3.1.UConv.4.bias     False          128                [128]            0            0\n",
      "   24                            down_4.1.UConv.0.weight     False       147456     [128, 128, 3, 3]    -1.57e-05        0.017\n",
      "   25                            down_4.1.UConv.1.weight     False          128                [128]            1            0\n",
      "   26                              down_4.1.UConv.1.bias     False          128                [128]            0            0\n",
      "   27                            down_4.1.UConv.3.weight     False       147456     [128, 128, 3, 3]     6.39e-05        0.017\n",
      "   28                            down_4.1.UConv.4.weight     False          128                [128]            1            0\n",
      "   29                              down_4.1.UConv.4.bias     False          128                [128]            0            0\n",
      "   30                           up_1.conv.UConv.0.weight     False       147456      [64, 256, 3, 3]    -4.08e-06       0.0121\n",
      "   31                           up_1.conv.UConv.1.weight     False           64                 [64]            1            0\n",
      "   32                             up_1.conv.UConv.1.bias     False           64                 [64]            0            0\n",
      "   33                           up_1.conv.UConv.3.weight     False        36864       [64, 64, 3, 3]     0.000201        0.024\n",
      "   34                           up_1.conv.UConv.4.weight     False           64                 [64]            1            0\n",
      "   35                             up_1.conv.UConv.4.bias     False           64                 [64]            0            0\n",
      "   36                           up_2.conv.UConv.0.weight     False        36864      [32, 128, 3, 3]     7.52e-05       0.0171\n",
      "   37                           up_2.conv.UConv.1.weight     False           32                 [32]            1            0\n",
      "   38                             up_2.conv.UConv.1.bias     False           32                 [32]            0            0\n",
      "   39                           up_2.conv.UConv.3.weight     False         9216       [32, 32, 3, 3]     0.000256       0.0341\n",
      "   40                           up_2.conv.UConv.4.weight     False           32                 [32]            1            0\n",
      "   41                             up_2.conv.UConv.4.bias     False           32                 [32]            0            0\n",
      "   42                           up_3.conv.UConv.0.weight     False         9216       [16, 64, 3, 3]    -0.000402       0.0241\n",
      "   43                           up_3.conv.UConv.1.weight     False           16                 [16]            1            0\n",
      "   44                             up_3.conv.UConv.1.bias     False           16                 [16]            0            0\n",
      "   45                           up_3.conv.UConv.3.weight     False         2304       [16, 16, 3, 3]    -0.000105       0.0477\n",
      "   46                           up_3.conv.UConv.4.weight     False           16                 [16]            1            0\n",
      "   47                             up_3.conv.UConv.4.bias     False           16                 [16]            0            0\n",
      "   48                     NHCHRConv.HConv.UConv.0.weight     False         4608       [16, 32, 3, 3]     0.000491        0.034\n",
      "   49                     NHCHRConv.HConv.UConv.1.weight     False           16                 [16]            1            0\n",
      "   50                       NHCHRConv.HConv.UConv.1.bias     False           16                 [16]            0            0\n",
      "   51                     NHCHRConv.HConv.UConv.3.weight     False         2304       [16, 16, 3, 3]     0.000319       0.0489\n",
      "   52                     NHCHRConv.HConv.UConv.4.weight     False           16                 [16]            1            0\n",
      "   53                       NHCHRConv.HConv.UConv.4.bias     False           16                 [16]            0            0\n",
      "   54                     NHCHRConv.XConv.UConv.0.weight      True         4608       [16, 32, 3, 3]     0.000288       0.0341\n",
      "   55                     NHCHRConv.XConv.UConv.1.weight      True           16                 [16]            1            0\n",
      "   56                       NHCHRConv.XConv.UConv.1.bias      True           16                 [16]            0            0\n",
      "   57                     NHCHRConv.XConv.UConv.3.weight      True         2304       [16, 16, 3, 3]     0.000987        0.048\n",
      "   58                     NHCHRConv.XConv.UConv.4.weight      True           16                 [16]            1            0\n",
      "   59                       NHCHRConv.XConv.UConv.4.bias      True           16                 [16]            0            0\n",
      "   60                     NHCHRConv.YConv.UConv.0.weight      True         4608       [16, 32, 3, 3]    -0.000116        0.034\n",
      "   61                     NHCHRConv.YConv.UConv.1.weight      True           16                 [16]            1            0\n",
      "   62                       NHCHRConv.YConv.UConv.1.bias      True           16                 [16]            0            0\n",
      "   63                     NHCHRConv.YConv.UConv.3.weight      True         2304       [16, 16, 3, 3]    -6.77e-05       0.0487\n",
      "   64                     NHCHRConv.YConv.UConv.4.weight      True           16                 [16]            1            0\n",
      "   65                       NHCHRConv.YConv.UConv.4.bias      True           16                 [16]            0            0\n",
      "   66                                    HOutconv.weight     False           16        [1, 16, 1, 1]       0.0291        0.115\n",
      "   67                                      HOutconv.bias     False            1                  [1]       -0.172          nan\n",
      "   68                                  XOutconv.0.weight      True           17        [1, 17, 1, 1]        0.093       0.0934\n",
      "   69                                    XOutconv.0.bias      True            1                  [1]       0.0195          nan\n",
      "   70                                  YOutconv.0.weight      True           17        [1, 17, 1, 1]      0.00237        0.142\n",
      "   71                                    YOutconv.0.bias      True            1                  [1]      -0.0488          nan\n",
      "Model Summary: 72 layers, 852485 parameters, 13988 gradients\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "model = NCHRNet(1, 1)\n",
    "# model_info(model)\n",
    "inp = torch.from_numpy(np.random.normal(0, 1, [10, 1, 64, 64]).astype(np.float32))\n",
    "H, coor = model(inp)\n",
    "\n",
    "print(H.shape, coor.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inconv.UConv.0.weight False\n",
      "inconv.UConv.1.weight False\n",
      "inconv.UConv.1.bias False\n",
      "inconv.UConv.3.weight False\n",
      "inconv.UConv.4.weight False\n",
      "inconv.UConv.4.bias False\n",
      "down_1.1.UConv.0.weight False\n",
      "down_1.1.UConv.1.weight False\n",
      "down_1.1.UConv.1.bias False\n",
      "down_1.1.UConv.3.weight False\n",
      "down_1.1.UConv.4.weight False\n",
      "down_1.1.UConv.4.bias False\n",
      "down_2.1.UConv.0.weight False\n",
      "down_2.1.UConv.1.weight False\n",
      "down_2.1.UConv.1.bias False\n",
      "down_2.1.UConv.3.weight False\n",
      "down_2.1.UConv.4.weight False\n",
      "down_2.1.UConv.4.bias False\n",
      "down_3.1.UConv.0.weight False\n",
      "down_3.1.UConv.1.weight False\n",
      "down_3.1.UConv.1.bias False\n",
      "down_3.1.UConv.3.weight False\n",
      "down_3.1.UConv.4.weight False\n",
      "down_3.1.UConv.4.bias False\n",
      "down_4.1.UConv.0.weight False\n",
      "down_4.1.UConv.1.weight False\n",
      "down_4.1.UConv.1.bias False\n",
      "down_4.1.UConv.3.weight False\n",
      "down_4.1.UConv.4.weight False\n",
      "down_4.1.UConv.4.bias False\n",
      "up_1.conv.UConv.0.weight False\n",
      "up_1.conv.UConv.1.weight False\n",
      "up_1.conv.UConv.1.bias False\n",
      "up_1.conv.UConv.3.weight False\n",
      "up_1.conv.UConv.4.weight False\n",
      "up_1.conv.UConv.4.bias False\n",
      "up_2.conv.UConv.0.weight False\n",
      "up_2.conv.UConv.1.weight False\n",
      "up_2.conv.UConv.1.bias False\n",
      "up_2.conv.UConv.3.weight False\n",
      "up_2.conv.UConv.4.weight False\n",
      "up_2.conv.UConv.4.bias False\n",
      "up_3.conv.UConv.0.weight False\n",
      "up_3.conv.UConv.1.weight False\n",
      "up_3.conv.UConv.1.bias False\n",
      "up_3.conv.UConv.3.weight False\n",
      "up_3.conv.UConv.4.weight False\n",
      "up_3.conv.UConv.4.bias False\n",
      "NHCHRConv.HConv.UConv.0.weight False\n",
      "NHCHRConv.HConv.UConv.1.weight False\n",
      "NHCHRConv.HConv.UConv.1.bias False\n",
      "NHCHRConv.HConv.UConv.3.weight False\n",
      "NHCHRConv.HConv.UConv.4.weight False\n",
      "NHCHRConv.HConv.UConv.4.bias False\n",
      "NHCHRConv.XConv.UConv.0.weight True\n",
      "NHCHRConv.XConv.UConv.1.weight True\n",
      "NHCHRConv.XConv.UConv.1.bias True\n",
      "NHCHRConv.XConv.UConv.3.weight True\n",
      "NHCHRConv.XConv.UConv.4.weight True\n",
      "NHCHRConv.XConv.UConv.4.bias True\n",
      "NHCHRConv.YConv.UConv.0.weight True\n",
      "NHCHRConv.YConv.UConv.1.weight True\n",
      "NHCHRConv.YConv.UConv.1.bias True\n",
      "NHCHRConv.YConv.UConv.3.weight True\n",
      "NHCHRConv.YConv.UConv.4.weight True\n",
      "NHCHRConv.YConv.UConv.4.bias True\n",
      "HOutconv.weight False\n",
      "HOutconv.bias False\n",
      "XOutconv.0.weight True\n",
      "XOutconv.0.bias True\n",
      "YOutconv.0.weight True\n",
      "YOutconv.0.bias True\n"
     ]
    }
   ],
   "source": [
    "## freeze x-y-conv layer\n",
    "# for (name, param) in model.named_parameters():\n",
    "#     if 'X' in name or 'Y' in name:\n",
    "#         param.requires_grad = False\n",
    "#     print(name, param.requires_grad)\n",
    "## freeze layers but not x-y-conv\n",
    "for (name, param) in model.named_parameters():\n",
    "    if 'X' not in name and 'Y' not in name:\n",
    "        param.requires_grad = False\n",
    "    print(name, param.requires_grad)\n",
    "# model_info(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential as S\n",
    "\"\"\"\n",
    "clear UNet implementation.\n",
    "\"\"\"\n",
    "class UNetConv(nn.Module):\n",
    "    \"\"\"\n",
    "    conv-bn-relu-conv-bn-relu\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(UNetConv, self).__init__()\n",
    "        self.UConv = S(\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(c_out, c_out, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.UConv(x)\n",
    "    \n",
    "class AtrousConv(nn.Module):\n",
    "    def __init__(self, c_in, c_out, dilation=(1,2,5,9)):\n",
    "        super(AtrousConv, self).__init__()\n",
    "        inter_out = int(c_out/2)\n",
    "\n",
    "#         self.conv_1x1_1 = S(\n",
    "#             nn.Conv2d(c_in, inter_out, kernel_size=1, bias=False),\n",
    "#             nn.BatchNorm2d(inter_out),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#         )\n",
    "        \n",
    "        self.conv_3x3_1 = S(\n",
    "            nn.Conv2d(c_in, inter_out, kernel_size=3, padding=dilation[0], bias=False, dilation=dilation[0]),\n",
    "            nn.BatchNorm2d(inter_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.conv_3x3_2 = S(\n",
    "            nn.Conv2d(c_in, inter_out, kernel_size=3, padding=dilation[1], bias=False, dilation=dilation[1]),\n",
    "            nn.BatchNorm2d(inter_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.conv_3x3_3 = S(\n",
    "            nn.Conv2d(c_in, inter_out, kernel_size=3, padding=dilation[2], bias=False, dilation=dilation[2]),\n",
    "            nn.BatchNorm2d(inter_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.conv_3x3_4 = S(\n",
    "            nn.Conv2d(c_in, inter_out, kernel_size=3, padding=dilation[3], bias=False, dilation=dilation[3]),\n",
    "            nn.BatchNorm2d(inter_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.out_conv = S(\n",
    "            nn.Conv2d(int(inter_out*4), c_out, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "#         x1 = self.conv_1x1_1(x)\n",
    "        x1 = self.conv_3x3_1(x)\n",
    "        x2 = self.conv_3x3_2(x)\n",
    "        x3 = self.conv_3x3_3(x)\n",
    "        x4 = self.conv_3x3_4(x)\n",
    "        out = self.out_conv(torch.cat([x1, x2, x3, x4], dim=1))\n",
    "        \n",
    "        return out\n",
    "        \n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"\n",
    "    Upscaling then double conv(implemented by https://github.com/milesial/Pytorch-UNet)\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out, bilinear=True):\n",
    "        super(Up, self).__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(c_in // 2, c_in // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = UNetConv(c_in, c_out)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "    \n",
    "\n",
    "class AUNet(nn.Module):\n",
    "    def __init__(self, c_in, n_classes, bilinear=True):\n",
    "        super(AUNet, self).__init__()\n",
    "        \n",
    "        c_base = 16\n",
    "        self.inconv = UNetConv(c_in, c_base)                              # 64*64\n",
    "        self.down_1 = S(nn.MaxPool2d(2), AtrousConv(c_base, c_base*2),)     # 32*32\n",
    "        self.down_2 = S(nn.MaxPool2d(2), AtrousConv(c_base*2, c_base*4),)   # 16*16\n",
    "#         self.down_3 = S(nn.MaxPool2d(2), AtrousConv(c_base*4, c_base*8, dilation=(1,2,3)),)   # 8*8\n",
    "#         self.down_4 = S(nn.MaxPool2d(2), AtrousConv(c_base*8, c_base*8, dilation=(1,2,3)),)   # 4*4\n",
    "#         self.up_1 = Up(c_base*16, c_base*4, bilinear)\n",
    "#         self.up_2 = Up(c_base*8, c_base*2, bilinear)\n",
    "        self.up_3 = Up(c_base*6, c_base*2, bilinear)\n",
    "        self.up_4 = Up(c_base*3, c_base*1, bilinear)\n",
    "#         self.up_1 = DUC(c_base*16, c_base*4, scale_factor=2)\n",
    "#         self.up_2 = DUC(c_base*8, c_base*2, scale_factor=2)\n",
    "#         self.up_3 = DUC(c_base*4, c_base*1, scale_factor=2)\n",
    "#         self.up_4 = DUC(c_base*2, c_base*1, scale_factor=2)\n",
    "        self.outconv = nn.Conv2d(c_base, n_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.inconv(x)\n",
    "        x2 = self.down_1(x1)\n",
    "        x3 = self.down_2(x2)\n",
    "#         x4 = self.down_3(x3)\n",
    "#         print(x1.shape, x2.shape, x4.shape, x3.shape)\n",
    "#         x5 = self.down_4(x4)\n",
    "#         x = self.up_1(x5, x4)\n",
    "#         x = self.up_2(x3, x2)\n",
    "#         print(x1.shape, x2.shape, x3.shape)\n",
    "        x = self.up_3(x3, x2)\n",
    "        x = self.up_4(x, x1)\n",
    "        logits = self.outconv(x)\n",
    "        return logits    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "layer                                               name  gradient   parameters                shape           mu        sigma\n",
      "    0                              inconv.UConv.0.weight      True          432        [16, 3, 3, 3]     -0.00142        0.109\n",
      "    1                              inconv.UConv.1.weight      True           16                 [16]            1            0\n",
      "    2                                inconv.UConv.1.bias      True           16                 [16]            0            0\n",
      "    3                              inconv.UConv.3.weight      True         2304       [16, 16, 3, 3]    -0.000408       0.0484\n",
      "    4                              inconv.UConv.4.weight      True           16                 [16]            1            0\n",
      "    5                                inconv.UConv.4.bias      True           16                 [16]            0            0\n",
      "    6                       down_1.1.conv_3x3_1.0.weight      True         2304       [16, 16, 3, 3]     0.000935       0.0488\n",
      "    7                       down_1.1.conv_3x3_1.1.weight      True           16                 [16]            1            0\n",
      "    8                         down_1.1.conv_3x3_1.1.bias      True           16                 [16]            0            0\n",
      "    9                       down_1.1.conv_3x3_2.0.weight      True         2304       [16, 16, 3, 3]    -0.000944       0.0482\n",
      "   10                       down_1.1.conv_3x3_2.1.weight      True           16                 [16]            1            0\n",
      "   11                         down_1.1.conv_3x3_2.1.bias      True           16                 [16]            0            0\n",
      "   12                       down_1.1.conv_3x3_3.0.weight      True         2304       [16, 16, 3, 3]    -0.000566       0.0487\n",
      "   13                       down_1.1.conv_3x3_3.1.weight      True           16                 [16]            1            0\n",
      "   14                         down_1.1.conv_3x3_3.1.bias      True           16                 [16]            0            0\n",
      "   15                       down_1.1.conv_3x3_4.0.weight      True         2304       [16, 16, 3, 3]      0.00055       0.0489\n",
      "   16                       down_1.1.conv_3x3_4.1.weight      True           16                 [16]            1            0\n",
      "   17                         down_1.1.conv_3x3_4.1.bias      True           16                 [16]            0            0\n",
      "   18                         down_1.1.out_conv.0.weight      True         2048       [32, 64, 1, 1]      0.00175        0.072\n",
      "   19                         down_1.1.out_conv.1.weight      True           32                 [32]            1            0\n",
      "   20                           down_1.1.out_conv.1.bias      True           32                 [32]            0            0\n",
      "   21                       down_2.1.conv_3x3_1.0.weight      True         9216       [32, 32, 3, 3]    -4.87e-05       0.0338\n",
      "   22                       down_2.1.conv_3x3_1.1.weight      True           32                 [32]            1            0\n",
      "   23                         down_2.1.conv_3x3_1.1.bias      True           32                 [32]            0            0\n",
      "   24                       down_2.1.conv_3x3_2.0.weight      True         9216       [32, 32, 3, 3]    -0.000587       0.0339\n",
      "   25                       down_2.1.conv_3x3_2.1.weight      True           32                 [32]            1            0\n",
      "   26                         down_2.1.conv_3x3_2.1.bias      True           32                 [32]            0            0\n",
      "   27                       down_2.1.conv_3x3_3.0.weight      True         9216       [32, 32, 3, 3]     -0.00022       0.0338\n",
      "   28                       down_2.1.conv_3x3_3.1.weight      True           32                 [32]            1            0\n",
      "   29                         down_2.1.conv_3x3_3.1.bias      True           32                 [32]            0            0\n",
      "   30                       down_2.1.conv_3x3_4.0.weight      True         9216       [32, 32, 3, 3]      0.00014        0.034\n",
      "   31                       down_2.1.conv_3x3_4.1.weight      True           32                 [32]            1            0\n",
      "   32                         down_2.1.conv_3x3_4.1.bias      True           32                 [32]            0            0\n",
      "   33                         down_2.1.out_conv.0.weight      True         8192      [64, 128, 1, 1]    -4.57e-05       0.0513\n",
      "   34                         down_2.1.out_conv.1.weight      True           64                 [64]            1            0\n",
      "   35                           down_2.1.out_conv.1.bias      True           64                 [64]            0            0\n",
      "   36                           up_3.conv.UConv.0.weight      True        27648       [32, 96, 3, 3]    -3.79e-05       0.0197\n",
      "   37                           up_3.conv.UConv.1.weight      True           32                 [32]            1            0\n",
      "   38                             up_3.conv.UConv.1.bias      True           32                 [32]            0            0\n",
      "   39                           up_3.conv.UConv.3.weight      True         9216       [32, 32, 3, 3]     0.000177       0.0342\n",
      "   40                           up_3.conv.UConv.4.weight      True           32                 [32]            1            0\n",
      "   41                             up_3.conv.UConv.4.bias      True           32                 [32]            0            0\n",
      "   42                           up_4.conv.UConv.0.weight      True         6912       [16, 48, 3, 3]    -0.000291       0.0278\n",
      "   43                           up_4.conv.UConv.1.weight      True           16                 [16]            1            0\n",
      "   44                             up_4.conv.UConv.1.bias      True           16                 [16]            0            0\n",
      "   45                           up_4.conv.UConv.3.weight      True         2304       [16, 16, 3, 3]     -0.00129       0.0477\n",
      "   46                           up_4.conv.UConv.4.weight      True           16                 [16]            1            0\n",
      "   47                             up_4.conv.UConv.4.bias      True           16                 [16]            0            0\n",
      "   48                                     outconv.weight      True          160       [10, 16, 1, 1]       0.0172        0.154\n",
      "   49                                       outconv.bias      True           10                 [10]      -0.0431        0.119\n",
      "Model Summary: 50 layers, 106138 parameters, 106138 gradients\n",
      "\n",
      "torch.Size([1, 32, 32, 32]) torch.Size([1, 16, 64, 64])\n",
      "0.03900003433227539\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import time\n",
    "model = AUNet(3, 10)\n",
    "model_info(model)\n",
    "inp = torch.from_numpy(np.random.normal(0, 1, [1, 3, 64, 64]).astype(np.float32))\n",
    "s = time.time()\n",
    "preds = model(inp)\n",
    "e = time.time()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DUC(nn.Module):\n",
    "    def __init__(self,c_in, c_out, scale_factor=4):\n",
    "        super(DUC, self).__init__()\n",
    "        \n",
    "        self.conv = UNetConv(c_in, c_out*scale_factor*scale_factor)\n",
    "        print(c_out*scale_factor*scale_factor)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(scale_factor)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class ADUNet(nn.Module):\n",
    "    def __init__(self, c_in, n_classes, bilinear=True):\n",
    "        super(ADUNet, self).__init__()\n",
    "        \n",
    "        c_base = 16\n",
    "        self.inconv = UNetConv(c_in, c_base)                              # 64*64\n",
    "        self.down_1 = S(nn.MaxPool2d(2), AtrousConv(c_base, c_base*2),)     # 32*32\n",
    "        self.down_2 = S(nn.MaxPool2d(2), AtrousConv(c_base*2, c_base*4),)   # 16*16\n",
    "#         self.down_3 = S(nn.MaxPool2d(2), AtrousConv(c_base*4, c_base*8, dilation=(1,2,3)),)   # 8*8\n",
    "#         self.down_4 = S(nn.MaxPool2d(2), AtrousConv(c_base*8, c_base*8, dilation=(1,2,3)),)   # 4*4\n",
    "#         self.up_1 = Up(c_base*16, c_base*4, bilinear)\n",
    "#         self.up_2 = Up(c_base*8, c_base*2, bilinear)\n",
    "#         self.up_3 = Up(c_base*6, c_base*2, bilinear)\n",
    "#         self.up_4 = Up(c_base*3, c_base*1, bilinear)\n",
    "#         self.up_1 = DUC(c_base*16, c_base*4, scale_factor=2)\n",
    "#         self.up_2 = DUC(c_base*8, c_base*2, scale_factor=2)\n",
    "#         self.up_3 = DUC(c_base*4, c_base*1, scale_factor=2)\n",
    "        self.duc = DUC(c_base*4, c_base*1, scale_factor=4)\n",
    "        self.outconv = nn.Conv2d(c_base, n_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.inconv(x)\n",
    "        x2 = self.down_1(x1)\n",
    "        x3 = self.down_2(x2)\n",
    "#         x4 = self.down_3(x3)\n",
    "#         print(x1.shape, x2.shape, x4.shape, x3.shape)\n",
    "#         x5 = self.down_4(x4)\n",
    "#         x = self.up_1(x5, x4)\n",
    "#         x = self.up_2(x3, x2)\n",
    "#         print(x1.shape, x2.shape, x3.shape)\n",
    "#         x = self.up_3(x3, x2)\n",
    "        x = self.duc(x3)\n",
    "        logits = self.outconv(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "\n",
      "layer                                               name  gradient   parameters                shape           mu        sigma\n",
      "    0                              inconv.UConv.0.weight      True          432        [16, 3, 3, 3]     -0.00648        0.109\n",
      "    1                              inconv.UConv.1.weight      True           16                 [16]            1            0\n",
      "    2                                inconv.UConv.1.bias      True           16                 [16]            0            0\n",
      "    3                              inconv.UConv.3.weight      True         2304       [16, 16, 3, 3]    -1.87e-05       0.0477\n",
      "    4                              inconv.UConv.4.weight      True           16                 [16]            1            0\n",
      "    5                                inconv.UConv.4.bias      True           16                 [16]            0            0\n",
      "    6                       down_1.1.conv_3x3_1.0.weight      True         2304       [16, 16, 3, 3]     -0.00129       0.0485\n",
      "    7                       down_1.1.conv_3x3_1.1.weight      True           16                 [16]            1            0\n",
      "    8                         down_1.1.conv_3x3_1.1.bias      True           16                 [16]            0            0\n",
      "    9                       down_1.1.conv_3x3_2.0.weight      True         2304       [16, 16, 3, 3]      0.00112       0.0479\n",
      "   10                       down_1.1.conv_3x3_2.1.weight      True           16                 [16]            1            0\n",
      "   11                         down_1.1.conv_3x3_2.1.bias      True           16                 [16]            0            0\n",
      "   12                       down_1.1.conv_3x3_3.0.weight      True         2304       [16, 16, 3, 3]    -0.000773       0.0485\n",
      "   13                       down_1.1.conv_3x3_3.1.weight      True           16                 [16]            1            0\n",
      "   14                         down_1.1.conv_3x3_3.1.bias      True           16                 [16]            0            0\n",
      "   15                       down_1.1.conv_3x3_4.0.weight      True         2304       [16, 16, 3, 3]    -0.000895       0.0481\n",
      "   16                       down_1.1.conv_3x3_4.1.weight      True           16                 [16]            1            0\n",
      "   17                         down_1.1.conv_3x3_4.1.bias      True           16                 [16]            0            0\n",
      "   18                         down_1.1.out_conv.0.weight      True         2048       [32, 64, 1, 1]    -0.000529       0.0721\n",
      "   19                         down_1.1.out_conv.1.weight      True           32                 [32]            1            0\n",
      "   20                           down_1.1.out_conv.1.bias      True           32                 [32]            0            0\n",
      "   21                       down_2.1.conv_3x3_1.0.weight      True         9216       [32, 32, 3, 3]    -0.000409       0.0341\n",
      "   22                       down_2.1.conv_3x3_1.1.weight      True           32                 [32]            1            0\n",
      "   23                         down_2.1.conv_3x3_1.1.bias      True           32                 [32]            0            0\n",
      "   24                       down_2.1.conv_3x3_2.0.weight      True         9216       [32, 32, 3, 3]     7.08e-05       0.0339\n",
      "   25                       down_2.1.conv_3x3_2.1.weight      True           32                 [32]            1            0\n",
      "   26                         down_2.1.conv_3x3_2.1.bias      True           32                 [32]            0            0\n",
      "   27                       down_2.1.conv_3x3_3.0.weight      True         9216       [32, 32, 3, 3]     0.000905       0.0339\n",
      "   28                       down_2.1.conv_3x3_3.1.weight      True           32                 [32]            1            0\n",
      "   29                         down_2.1.conv_3x3_3.1.bias      True           32                 [32]            0            0\n",
      "   30                       down_2.1.conv_3x3_4.0.weight      True         9216       [32, 32, 3, 3]     0.000161       0.0341\n",
      "   31                       down_2.1.conv_3x3_4.1.weight      True           32                 [32]            1            0\n",
      "   32                         down_2.1.conv_3x3_4.1.bias      True           32                 [32]            0            0\n",
      "   33                         down_2.1.out_conv.0.weight      True         8192      [64, 128, 1, 1]     0.000246       0.0511\n",
      "   34                         down_2.1.out_conv.1.weight      True           64                 [64]            1            0\n",
      "   35                           down_2.1.out_conv.1.bias      True           64                 [64]            0            0\n",
      "   36                            duc.conv.UConv.0.weight      True       147456      [256, 64, 3, 3]    -0.000127       0.0241\n",
      "   37                            duc.conv.UConv.1.weight      True          256                [256]            1            0\n",
      "   38                              duc.conv.UConv.1.bias      True          256                [256]            0            0\n",
      "   39                            duc.conv.UConv.3.weight      True       589824     [256, 256, 3, 3]      2.4e-06        0.012\n",
      "   40                            duc.conv.UConv.4.weight      True          256                [256]            1            0\n",
      "   41                              duc.conv.UConv.4.bias      True          256                [256]            0            0\n",
      "   42                                     outconv.weight      True          160       [10, 16, 1, 1]      -0.0158        0.143\n",
      "   43                                       outconv.bias      True           10                 [10]       0.0791        0.146\n",
      "Model Summary: 44 layers, 798170 parameters, 798170 gradients\n",
      "\n",
      "0.023999929428100586\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import time\n",
    "model = ADUNet(3, 10)\n",
    "model_info(model)\n",
    "inp = torch.from_numpy(np.random.normal(0, 1, [1, 3, 64, 64]).astype(np.float32))\n",
    "s = time.time()\n",
    "preds = model(inp)\n",
    "e = time.time()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class Up(nn.Module):\n",
    "    \"\"\"\n",
    "    Upscaling then double conv(implemented by https://github.com/milesial/Pytorch-UNet)\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out, bilinear=True):\n",
    "        super(Up, self).__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(c_in // 2, c_in // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = UNetConv(c_in, c_out)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)    \n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        bilinear = True\n",
    "        self.inplanes = 16\n",
    "        c_base = 16\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(1, c_base, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, c_base, layers[0])\n",
    "        self.layer2 = self._make_layer(block, c_base*2, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, c_base*4, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, c_base*8, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        \n",
    "        self.up_1 = Up(c_base*12, c_base*4, bilinear)\n",
    "        self.up_2 = Up(c_base*6, c_base*2, bilinear)\n",
    "        self.up_3 = Up(c_base*3, c_base*1, bilinear)\n",
    "        self.up_4 = Up(c_base*2, c_base*1, bilinear)\n",
    "        \n",
    "        self.outconv = nn.Conv2d(c_base, 1, kernel_size=1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x1 = self.relu(x)\n",
    "        x2 = self.layer1(self.maxpool(x1))\n",
    "        x3 = self.layer2(x2)\n",
    "        x4 = self.layer3(x3)\n",
    "        x5 = self.layer4(x4)\n",
    "        x = self.up_1(x5, x4)\n",
    "        x = self.up_2(x, x3)\n",
    "        x = self.up_3(x, x2)\n",
    "        x = self.up_4(x, x1)\n",
    "        x = self.outconv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"ResNet-50 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "layer                                               name  gradient   parameters                shape           mu        sigma\n",
      "    0                                       conv1.weight      True          144        [16, 1, 3, 3]     2.86e-05        0.126\n",
      "    1                                         bn1.weight      True           16                 [16]            1            0\n",
      "    2                                           bn1.bias      True           16                 [16]            0            0\n",
      "    3                              layer1.0.conv1.weight      True          256       [16, 16, 1, 1]     -0.00419        0.363\n",
      "    4                                layer1.0.bn1.weight      True           16                 [16]            1            0\n",
      "    5                                  layer1.0.bn1.bias      True           16                 [16]            0            0\n",
      "    6                              layer1.0.conv2.weight      True         2304       [16, 16, 3, 3]     0.000979        0.117\n",
      "    7                                layer1.0.bn2.weight      True           16                 [16]            1            0\n",
      "    8                                  layer1.0.bn2.bias      True           16                 [16]            0            0\n",
      "    9                              layer1.0.conv3.weight      True          256       [16, 16, 1, 1]       0.0342        0.326\n",
      "   10                                layer1.0.bn3.weight      True           16                 [16]            1            0\n",
      "   11                                  layer1.0.bn3.bias      True           16                 [16]            0            0\n",
      "   12                              layer1.1.conv1.weight      True          256       [16, 16, 1, 1]       0.0237        0.337\n",
      "   13                                layer1.1.bn1.weight      True           16                 [16]            1            0\n",
      "   14                                  layer1.1.bn1.bias      True           16                 [16]            0            0\n",
      "   15                              layer1.1.conv2.weight      True         2304       [16, 16, 3, 3]     -0.00221         0.12\n",
      "   16                                layer1.1.bn2.weight      True           16                 [16]            1            0\n",
      "   17                                  layer1.1.bn2.bias      True           16                 [16]            0            0\n",
      "   18                              layer1.1.conv3.weight      True          256       [16, 16, 1, 1]       0.0428        0.363\n",
      "   19                                layer1.1.bn3.weight      True           16                 [16]            1            0\n",
      "   20                                  layer1.1.bn3.bias      True           16                 [16]            0            0\n",
      "   21                              layer1.2.conv1.weight      True          256       [16, 16, 1, 1]      -0.0395        0.334\n",
      "   22                                layer1.2.bn1.weight      True           16                 [16]            1            0\n",
      "   23                                  layer1.2.bn1.bias      True           16                 [16]            0            0\n",
      "   24                              layer1.2.conv2.weight      True         2304       [16, 16, 3, 3]     -0.00385        0.118\n",
      "   25                                layer1.2.bn2.weight      True           16                 [16]            1            0\n",
      "   26                                  layer1.2.bn2.bias      True           16                 [16]            0            0\n",
      "   27                              layer1.2.conv3.weight      True          256       [16, 16, 1, 1]       0.0274        0.347\n",
      "   28                                layer1.2.bn3.weight      True           16                 [16]            1            0\n",
      "   29                                  layer1.2.bn3.bias      True           16                 [16]            0            0\n",
      "   30                              layer2.0.conv1.weight      True          512       [32, 16, 1, 1]      -0.0016        0.255\n",
      "   31                                layer2.0.bn1.weight      True           32                 [32]            1            0\n",
      "   32                                  layer2.0.bn1.bias      True           32                 [32]            0            0\n",
      "   33                              layer2.0.conv2.weight      True         9216       [32, 32, 3, 3]    -0.000137       0.0831\n",
      "   34                                layer2.0.bn2.weight      True           32                 [32]            1            0\n",
      "   35                                  layer2.0.bn2.bias      True           32                 [32]            0            0\n",
      "   36                              layer2.0.conv3.weight      True         1024       [32, 32, 1, 1]     -0.00349        0.246\n",
      "   37                                layer2.0.bn3.weight      True           32                 [32]            1            0\n",
      "   38                                  layer2.0.bn3.bias      True           32                 [32]            0            0\n",
      "   39                       layer2.0.downsample.0.weight      True          512       [32, 16, 1, 1]    -3.63e-06        0.258\n",
      "   40                       layer2.0.downsample.1.weight      True           32                 [32]            1            0\n",
      "   41                         layer2.0.downsample.1.bias      True           32                 [32]            0            0\n",
      "   42                              layer2.1.conv1.weight      True         1024       [32, 32, 1, 1]      0.00752        0.253\n",
      "   43                                layer2.1.bn1.weight      True           32                 [32]            1            0\n",
      "   44                                  layer2.1.bn1.bias      True           32                 [32]            0            0\n",
      "   45                              layer2.1.conv2.weight      True         9216       [32, 32, 3, 3]     9.45e-06       0.0842\n",
      "   46                                layer2.1.bn2.weight      True           32                 [32]            1            0\n",
      "   47                                  layer2.1.bn2.bias      True           32                 [32]            0            0\n",
      "   48                              layer2.1.conv3.weight      True         1024       [32, 32, 1, 1]     -0.00944        0.245\n",
      "   49                                layer2.1.bn3.weight      True           32                 [32]            1            0\n",
      "   50                                  layer2.1.bn3.bias      True           32                 [32]            0            0\n",
      "   51                              layer2.2.conv1.weight      True         1024       [32, 32, 1, 1]       -0.011        0.241\n",
      "   52                                layer2.2.bn1.weight      True           32                 [32]            1            0\n",
      "   53                                  layer2.2.bn1.bias      True           32                 [32]            0            0\n",
      "   54                              layer2.2.conv2.weight      True         9216       [32, 32, 3, 3]     -0.00116       0.0819\n",
      "   55                                layer2.2.bn2.weight      True           32                 [32]            1            0\n",
      "   56                                  layer2.2.bn2.bias      True           32                 [32]            0            0\n",
      "   57                              layer2.2.conv3.weight      True         1024       [32, 32, 1, 1]      0.00515        0.249\n",
      "   58                                layer2.2.bn3.weight      True           32                 [32]            1            0\n",
      "   59                                  layer2.2.bn3.bias      True           32                 [32]            0            0\n",
      "   60                              layer2.3.conv1.weight      True         1024       [32, 32, 1, 1]      0.00632        0.254\n",
      "   61                                layer2.3.bn1.weight      True           32                 [32]            1            0\n",
      "   62                                  layer2.3.bn1.bias      True           32                 [32]            0            0\n",
      "   63                              layer2.3.conv2.weight      True         9216       [32, 32, 3, 3]     0.000753       0.0833\n",
      "   64                                layer2.3.bn2.weight      True           32                 [32]            1            0\n",
      "   65                                  layer2.3.bn2.bias      True           32                 [32]            0            0\n",
      "   66                              layer2.3.conv3.weight      True         1024       [32, 32, 1, 1]      -0.0117        0.251\n",
      "   67                                layer2.3.bn3.weight      True           32                 [32]            1            0\n",
      "   68                                  layer2.3.bn3.bias      True           32                 [32]            0            0\n",
      "   69                              layer3.0.conv1.weight      True         2048       [64, 32, 1, 1]     -0.00561        0.178\n",
      "   70                                layer3.0.bn1.weight      True           64                 [64]            1            0\n",
      "   71                                  layer3.0.bn1.bias      True           64                 [64]            0            0\n",
      "   72                              layer3.0.conv2.weight      True        36864       [64, 64, 3, 3]    -0.000166       0.0586\n",
      "   73                                layer3.0.bn2.weight      True           64                 [64]            1            0\n",
      "   74                                  layer3.0.bn2.bias      True           64                 [64]            0            0\n",
      "   75                              layer3.0.conv3.weight      True         4096       [64, 64, 1, 1]     -0.00257        0.178\n",
      "   76                                layer3.0.bn3.weight      True           64                 [64]            1            0\n",
      "   77                                  layer3.0.bn3.bias      True           64                 [64]            0            0\n",
      "   78                       layer3.0.downsample.0.weight      True         2048       [64, 32, 1, 1]      0.00327        0.175\n",
      "   79                       layer3.0.downsample.1.weight      True           64                 [64]            1            0\n",
      "   80                         layer3.0.downsample.1.bias      True           64                 [64]            0            0\n",
      "   81                              layer3.1.conv1.weight      True         4096       [64, 64, 1, 1]    -0.000694        0.177\n",
      "   82                                layer3.1.bn1.weight      True           64                 [64]            1            0\n",
      "   83                                  layer3.1.bn1.bias      True           64                 [64]            0            0\n",
      "   84                              layer3.1.conv2.weight      True        36864       [64, 64, 3, 3]     0.000174       0.0587\n",
      "   85                                layer3.1.bn2.weight      True           64                 [64]            1            0\n",
      "   86                                  layer3.1.bn2.bias      True           64                 [64]            0            0\n",
      "   87                              layer3.1.conv3.weight      True         4096       [64, 64, 1, 1]       0.0038        0.172\n",
      "   88                                layer3.1.bn3.weight      True           64                 [64]            1            0\n",
      "   89                                  layer3.1.bn3.bias      True           64                 [64]            0            0\n",
      "   90                              layer3.2.conv1.weight      True         4096       [64, 64, 1, 1]      -0.0015        0.177\n",
      "   91                                layer3.2.bn1.weight      True           64                 [64]            1            0\n",
      "   92                                  layer3.2.bn1.bias      True           64                 [64]            0            0\n",
      "   93                              layer3.2.conv2.weight      True        36864       [64, 64, 3, 3]    -5.57e-05       0.0592\n",
      "   94                                layer3.2.bn2.weight      True           64                 [64]            1            0\n",
      "   95                                  layer3.2.bn2.bias      True           64                 [64]            0            0\n",
      "   96                              layer3.2.conv3.weight      True         4096       [64, 64, 1, 1]      0.00231        0.177\n",
      "   97                                layer3.2.bn3.weight      True           64                 [64]            1            0\n",
      "   98                                  layer3.2.bn3.bias      True           64                 [64]            0            0\n",
      "   99                              layer3.3.conv1.weight      True         4096       [64, 64, 1, 1]     0.000272        0.181\n",
      "  100                                layer3.3.bn1.weight      True           64                 [64]            1            0\n",
      "  101                                  layer3.3.bn1.bias      True           64                 [64]            0            0\n",
      "  102                              layer3.3.conv2.weight      True        36864       [64, 64, 3, 3]    -0.000605       0.0588\n",
      "  103                                layer3.3.bn2.weight      True           64                 [64]            1            0\n",
      "  104                                  layer3.3.bn2.bias      True           64                 [64]            0            0\n",
      "  105                              layer3.3.conv3.weight      True         4096       [64, 64, 1, 1]     -0.00431        0.178\n",
      "  106                                layer3.3.bn3.weight      True           64                 [64]            1            0\n",
      "  107                                  layer3.3.bn3.bias      True           64                 [64]            0            0\n",
      "  108                              layer3.4.conv1.weight      True         4096       [64, 64, 1, 1]    -0.000509        0.175\n",
      "  109                                layer3.4.bn1.weight      True           64                 [64]            1            0\n",
      "  110                                  layer3.4.bn1.bias      True           64                 [64]            0            0\n",
      "  111                              layer3.4.conv2.weight      True        36864       [64, 64, 3, 3]     0.000838        0.059\n",
      "  112                                layer3.4.bn2.weight      True           64                 [64]            1            0\n",
      "  113                                  layer3.4.bn2.bias      True           64                 [64]            0            0\n",
      "  114                              layer3.4.conv3.weight      True         4096       [64, 64, 1, 1]    -5.62e-05        0.176\n",
      "  115                                layer3.4.bn3.weight      True           64                 [64]            1            0\n",
      "  116                                  layer3.4.bn3.bias      True           64                 [64]            0            0\n",
      "  117                              layer3.5.conv1.weight      True         4096       [64, 64, 1, 1]     -0.00279        0.174\n",
      "  118                                layer3.5.bn1.weight      True           64                 [64]            1            0\n",
      "  119                                  layer3.5.bn1.bias      True           64                 [64]            0            0\n",
      "  120                              layer3.5.conv2.weight      True        36864       [64, 64, 3, 3]     0.000328       0.0588\n",
      "  121                                layer3.5.bn2.weight      True           64                 [64]            1            0\n",
      "  122                                  layer3.5.bn2.bias      True           64                 [64]            0            0\n",
      "  123                              layer3.5.conv3.weight      True         4096       [64, 64, 1, 1]     -0.00326        0.177\n",
      "  124                                layer3.5.bn3.weight      True           64                 [64]            1            0\n",
      "  125                                  layer3.5.bn3.bias      True           64                 [64]            0            0\n",
      "  126                              layer4.0.conv1.weight      True         8192      [128, 64, 1, 1]     -0.00063        0.125\n",
      "  127                                layer4.0.bn1.weight      True          128                [128]            1            0\n",
      "  128                                  layer4.0.bn1.bias      True          128                [128]            0            0\n",
      "  129                              layer4.0.conv2.weight      True       147456     [128, 128, 3, 3]     7.48e-05       0.0416\n",
      "  130                                layer4.0.bn2.weight      True          128                [128]            1            0\n",
      "  131                                  layer4.0.bn2.bias      True          128                [128]            0            0\n",
      "  132                              layer4.0.conv3.weight      True        16384     [128, 128, 1, 1]    -6.36e-05        0.126\n",
      "  133                                layer4.0.bn3.weight      True          128                [128]            1            0\n",
      "  134                                  layer4.0.bn3.bias      True          128                [128]            0            0\n",
      "  135                       layer4.0.downsample.0.weight      True         8192      [128, 64, 1, 1]     -0.00405        0.124\n",
      "  136                       layer4.0.downsample.1.weight      True          128                [128]            1            0\n",
      "  137                         layer4.0.downsample.1.bias      True          128                [128]            0            0\n",
      "  138                              layer4.1.conv1.weight      True        16384     [128, 128, 1, 1]     -0.00169        0.125\n",
      "  139                                layer4.1.bn1.weight      True          128                [128]            1            0\n",
      "  140                                  layer4.1.bn1.bias      True          128                [128]            0            0\n",
      "  141                              layer4.1.conv2.weight      True       147456     [128, 128, 3, 3]    -0.000135       0.0417\n",
      "  142                                layer4.1.bn2.weight      True          128                [128]            1            0\n",
      "  143                                  layer4.1.bn2.bias      True          128                [128]            0            0\n",
      "  144                              layer4.1.conv3.weight      True        16384     [128, 128, 1, 1]     0.000822        0.124\n",
      "  145                                layer4.1.bn3.weight      True          128                [128]            1            0\n",
      "  146                                  layer4.1.bn3.bias      True          128                [128]            0            0\n",
      "  147                              layer4.2.conv1.weight      True        16384     [128, 128, 1, 1]       0.0011        0.125\n",
      "  148                                layer4.2.bn1.weight      True          128                [128]            1            0\n",
      "  149                                  layer4.2.bn1.bias      True          128                [128]            0            0\n",
      "  150                              layer4.2.conv2.weight      True       147456     [128, 128, 3, 3]     1.33e-05       0.0417\n",
      "  151                                layer4.2.bn2.weight      True          128                [128]            1            0\n",
      "  152                                  layer4.2.bn2.bias      True          128                [128]            0            0\n",
      "  153                              layer4.2.conv3.weight      True        16384     [128, 128, 1, 1]      0.00104        0.125\n",
      "  154                                layer4.2.bn3.weight      True          128                [128]            1            0\n",
      "  155                                  layer4.2.bn3.bias      True          128                [128]            0            0\n",
      "  156                           up_1.conv.UConv.0.weight      True       110592      [64, 192, 3, 3]    -0.000204       0.0588\n",
      "  157                           up_1.conv.UConv.1.weight      True           64                 [64]            1            0\n",
      "  158                             up_1.conv.UConv.1.bias      True           64                 [64]            0            0\n",
      "  159                           up_1.conv.UConv.3.weight      True        36864       [64, 64, 3, 3]    -0.000156       0.0588\n",
      "  160                           up_1.conv.UConv.4.weight      True           64                 [64]            1            0\n",
      "  161                             up_1.conv.UConv.4.bias      True           64                 [64]            0            0\n",
      "  162                           up_2.conv.UConv.0.weight      True        27648       [32, 96, 3, 3]    -0.000434        0.084\n",
      "  163                           up_2.conv.UConv.1.weight      True           32                 [32]            1            0\n",
      "  164                             up_2.conv.UConv.1.bias      True           32                 [32]            0            0\n",
      "  165                           up_2.conv.UConv.3.weight      True         9216       [32, 32, 3, 3]     0.000418       0.0836\n",
      "  166                           up_2.conv.UConv.4.weight      True           32                 [32]            1            0\n",
      "  167                             up_2.conv.UConv.4.bias      True           32                 [32]            0            0\n",
      "  168                           up_3.conv.UConv.0.weight      True         6912       [16, 48, 3, 3]     -0.00124         0.12\n",
      "  169                           up_3.conv.UConv.1.weight      True           16                 [16]            1            0\n",
      "  170                             up_3.conv.UConv.1.bias      True           16                 [16]            0            0\n",
      "  171                           up_3.conv.UConv.3.weight      True         2304       [16, 16, 3, 3]    -2.04e-06        0.115\n",
      "  172                           up_3.conv.UConv.4.weight      True           16                 [16]            1            0\n",
      "  173                             up_3.conv.UConv.4.bias      True           16                 [16]            0            0\n",
      "  174                           up_4.conv.UConv.0.weight      True         4608       [16, 32, 3, 3]    -0.000923        0.117\n",
      "  175                           up_4.conv.UConv.1.weight      True           16                 [16]            1            0\n",
      "  176                             up_4.conv.UConv.1.bias      True           16                 [16]            0            0\n",
      "  177                           up_4.conv.UConv.3.weight      True         2304       [16, 16, 3, 3]     -0.00126        0.117\n",
      "  178                           up_4.conv.UConv.4.weight      True           16                 [16]            1            0\n",
      "  179                             up_4.conv.UConv.4.bias      True           16                 [16]            0            0\n",
      "  180                                     outconv.weight      True           16        [1, 16, 1, 1]       -0.197         1.42\n",
      "  181                                       outconv.bias      True            1                  [1]        0.163          nan\n",
      "Model Summary: 182 layers, 1.07178e+06 parameters, 1.07178e+06 gradients\n",
      "\n",
      "torch.Size([1, 1, 64, 64])\n",
      "0.04699969291687012\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import time\n",
    "model = resnet50()\n",
    "model_info(model)\n",
    "inp = torch.from_numpy(np.random.normal(0, 1, [1, 1, 64, 64]).astype(np.float32))\n",
    "s = time.time()\n",
    "preds = model(inp)\n",
    "print(preds.shape)\n",
    "e = time.time()\n",
    "print(e-s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备、特征提取与微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 微调全连接层\n",
    "model = torchvision.models.resnet18(pretrianed=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(512, 10) # Replace the last fc layer\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "# 以较大学习率微调全连接层，较小学习率微调卷积层\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "finetuned_parameters = list(map(id, model.fc.parameters()))\n",
    "conv_parmeters = (p for p in model.parameters() if id(p) not in finetuned_parameters)\n",
    "parameters = [{'params': conv_parameters, 'lr':1e-3},\n",
    "              {'params': model.fc.parameters()}]\n",
    "optimizer = torch.optim.SGD(parameters, lr=1e-2, momentum=0.9, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常用训练和验证数据预处理\n",
    "# 其中ToTensor操作会将PIL.Image或形状H×W×D，数值范围为[0,255]的ndarray转换为形状D×H×W，数值范围为[0.0，1.0]的torch.Tensor\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(size=224,\n",
    "                                             scale=(0.08, 1.0)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                     std=(0.229, 0.224, 0.225)),\n",
    " ])\n",
    " val_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                     std=(0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练\n",
    "## 训练基本代码框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练基本代码框架\n",
    "for t in epoch(80):\n",
    "    for images, labels in tqdm.tqdm(train_loader, desc='Epoch %3d' %(t+1)):\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        scores = model(images)\n",
    "        loss = loss_function(scores, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学习率衰减"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到当前学习率\n",
    "# If there is one global learning rate(which is the common case)\n",
    "lr = next(iter(optimizer.param_groups))['lr']\n",
    "\n",
    "# If there are multiple learning rates for different layers.\n",
    "all_lr = []\n",
    "for param_group in optimizer.param_groups:\n",
    "    all_lr.append(param_group['lr'])\n",
    "    \n",
    "# 学习率衰减\n",
    "# Reduce learning rate when validation accuarcy plateau.\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, verbose=True)\n",
    "for t in range(0, 80):\n",
    "    train(...); val(...)\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "# Cosine annealing learning rate.\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80)\n",
    "# Reduce learning rate by 10 at given epochs.\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 70], gamma=0.1)\n",
    "for t in range(0, 80):\n",
    "    scheduler.step()    \n",
    "    train(...); val(...)\n",
    "\n",
    "# Learning rate warmup by 10 epochs.\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda t: t / 10)\n",
    "for t in range(0, 10):\n",
    "    scheduler.step()\n",
    "    train(...); val(...)\n",
    "\n",
    "# Step learning rate decay\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "for t in range(0, 10):\n",
    "    scheduler.step()\n",
    "    train(...); val(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度检验与clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型保存与导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer': {'state': {}, 'param_groups': [{'eps': 1e-08, 'lr': 0.01, 'betas': (0.9, 0.999), 'amsgrad': False, 'params': [2511406941960, 2511406942032], 'weight_decay': 0}]}, 'epcoh': 10, 'state_dict': OrderedDict([('linear.weight', tensor([[-0.0343, -0.0826, -0.0592,  ..., -0.0346, -0.0260,  0.0300],\n",
      "        [-0.0804,  0.0180,  0.0716,  ..., -0.0354,  0.0807, -0.0505],\n",
      "        [ 0.0981, -0.0978, -0.0455,  ...,  0.0182, -0.0366,  0.0263],\n",
      "        ...,\n",
      "        [ 0.0200,  0.0230, -0.0919,  ...,  0.0215, -0.0111,  0.0640],\n",
      "        [ 0.0044, -0.0459,  0.0360,  ..., -0.0753,  0.0333,  0.0291],\n",
      "        [-0.0323,  0.0726, -0.0105,  ...,  0.0155,  0.0662,  0.0221]])), ('linear.bias', tensor([ 0.0585,  0.0424, -0.0641, -0.0947,  0.0217,  0.0401, -0.0748,  0.0789,\n",
      "        -0.0505, -0.0208,  0.0741,  0.0627,  0.0322, -0.0263, -0.0026,  0.0054,\n",
      "        -0.0913, -0.0785, -0.0099,  0.0071,  0.0515,  0.0358, -0.0862,  0.0155,\n",
      "        -0.0215, -0.0404,  0.0097, -0.0053,  0.0829, -0.0823,  0.0351,  0.0534,\n",
      "        -0.0390,  0.0064,  0.0962,  0.0160, -0.0805, -0.0876, -0.0975, -0.0542,\n",
      "        -0.0245,  0.0854,  0.0614, -0.0774,  0.0042,  0.0912,  0.0531,  0.0719,\n",
      "         0.0857, -0.0031,  0.0631, -0.0298, -0.0957,  0.0759, -0.0522,  0.0241,\n",
      "         0.0277,  0.0835, -0.0482, -0.0586, -0.0623, -0.0543,  0.0413,  0.0592,\n",
      "        -0.0088, -0.0693, -0.0907,  0.0425,  0.0739, -0.0499,  0.0108, -0.0043,\n",
      "         0.0038, -0.0243, -0.0738, -0.0327,  0.0104,  0.0414,  0.0349,  0.0060,\n",
      "        -0.0737,  0.0162, -0.0071,  0.0510,  0.0603, -0.0453,  0.0003,  0.0486,\n",
      "         0.0505, -0.0690,  0.0753, -0.0460,  0.0193, -0.0064,  0.0519, -0.0122,\n",
      "         0.0941,  0.0488, -0.0224,  0.0149,  0.0118, -0.0790,  0.0731, -0.0672,\n",
      "         0.0249,  0.0167, -0.0355, -0.0006,  0.0246,  0.0798,  0.0424, -0.0007,\n",
      "         0.0849, -0.0641,  0.0142,  0.0325, -0.0482, -0.0996,  0.0215,  0.0522,\n",
      "         0.0471,  0.0390,  0.0264, -0.0301,  0.0206, -0.0885, -0.0871, -0.0716]))])}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 保存与加载断点\n",
    "# 注意为了能够恢复训练，我们需要同时保存模型和优化器的状态，以及当前的训练轮数。\n",
    "# Save checkpoinit.\n",
    "optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()), lr=0.01)\n",
    "epoch = 10\n",
    "current_acc = 0.6\n",
    "best_acc = 0.5\n",
    "resume = True\n",
    "is_best = current_acc > best_acc\n",
    "best_acc = max(best_acc, current_acc)\n",
    "checkpoint = {\n",
    "    'best_acc': best_acc,\n",
    "    'epoch': t+1,\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "}\n",
    "model_path = os.path.join('model', 'checkpoint.pth.tar')\n",
    "torch.save(checkpoint, model_path)\n",
    "if is_best:\n",
    "    shutil.copy('checkpoint.pth.tar', model_path)\n",
    "    \n",
    "# Load checkpoint\n",
    "if resume:\n",
    "    model_path = os.path.join('model', 'checkpoint.pth.tar')\n",
    "    assert os.path.isfile(model_path)\n",
    "    checkpoint = torch.load(model_path)\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print('Load checkpoint at epoch %d.' % start_epoch)\n",
    "\n",
    "\n",
    "\n",
    "# states = {\"state_dict\":model.state_dict(),\n",
    "#                  \"epcoh\":epoch,\n",
    "#                  \"optimizer\":optimizer.state_dict(),}\n",
    "#                  #\"best_acc\":accuracy,}\n",
    "# torch.save(states, \"./model_pred.pth\")\n",
    "\n",
    "# states = torch.load(\"./model_pred.pth\")\n",
    "print(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多GPU\n",
    "## 单机多GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 注意事项\n",
    "\n",
    "PyTorch其他注意事项\n",
    "\n",
    "模型定义\n",
    "\n",
    "建议有参数的层和汇合（pooling）层使用torch.nn模块定义，激活函数直接使用torch.nn.functional。torch.nn模块和torch.nn.functional的区别在于，torch.nn模块在计算时底层调用了torch.nn.functional，但torch.nn模块包括该层参数，还可以应对训练和测试两种网络状态。使用torch.nn.functional时要注意网络状态，如\n",
    "def forward(self, x):\n",
    "    ...\n",
    "    x = torch.nn.functional.dropout(x, p=0.5, training=self.training)\n",
    "model(x)前用model.train()和model.eval()切换网络状态。\n",
    "不需要计算梯度的代码块用with torch.no_grad()包含起来。model.eval()和torch.no_grad()的区别在于，model.eval()是将网络切换为测试状态，例如BN和随机失活（dropout）在训练和测试阶段使用不同的计算方法。torch.no_grad()是关闭PyTorch张量的自动求导机制，以减少存储使用和加速计算，得到的结果无法进行loss.backward()。\n",
    "torch.nn.CrossEntropyLoss的输入不需要经过Softmax。torch.nn.CrossEntropyLoss等价于torch.nn.functional.log_softmax + torch.nn.NLLLoss。\n",
    "loss.backward()前用optimizer.zero_grad()清除累积梯度。optimizer.zero_grad()和model.zero_grad()效果一样。\n",
    "\n",
    "PyTorch性能与调试\n",
    "\n",
    "torch.utils.data.DataLoader中尽量设置pin_memory=True，对特别小的数据集如MNIST设置pin_memory=False反而更快一些。num_workers的设置需要在实验中找到最快的取值。\n",
    "用del及时删除不用的中间变量，节约GPU存储。\n",
    "使用inplace操作可节约GPU存储，如\n",
    "x = torch.nn.functional.relu(x, inplace=True)\n",
    "此外，还可以通过torch.utils.checkpoint前向传播时只保留一部分中间结果来节约GPU存储使用，在反向传播时需要的内容从最近中间结果中计算得到。\n",
    "\n",
    "减少CPU和GPU之间的数据传输。例如如果你想知道一个epoch中每个mini-batch的loss和准确率，先将它们累积在GPU中等一个epoch结束之后一起传输回CPU会比每个mini-batch都进行一次GPU到CPU的传输更快。\n",
    "使用半精度浮点数half()会有一定的速度提升，具体效率依赖于GPU型号。需要小心数值精度过低带来的稳定性问题。\n",
    "时常使用assert tensor.size() == (N, D, H, W)作为调试手段，确保张量维度和你设想中一致。\n",
    "除了标记y外，尽量少使用一维张量，使用n*1的二维张量代替，可以避免一些意想不到的一维张量计算结果。\n",
    "统计代码各部分耗时\n",
    "with torch.autograd.profiler.profile(enabled=True, use_cuda=False) as profile:\n",
    "    ...\n",
    "print(profile)\n",
    "或者在命令行运行\n",
    "\n",
    "python -m torch.utils.bottleneck main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Pytoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PixelShuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 16, 16])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "ps = nn.PixelShuffle(2)\n",
    "tensor = torch.Tensor(1, 4, 8, 8)\n",
    "ps_tensor = ps(tensor)\n",
    "ps_tensor.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.988px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
